{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from random import sample\n",
    "from cmath import exp, sqrt\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# headers = [\"ID of from node\",\"ID of to node\", \"weight\", \"timestamp\"]\n",
    "# Graph = pd.read_csv(\"./Prosper_loans.csv\", names=headers, sep=' ').drop_duplicates()\n",
    "# V=np.unique((Graph['ID of from node']._append(Graph['ID of to node'])).values)\n",
    "# V_num = V.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for testing purposes; using way smaller dataset\n",
    "headers = [\"ID of from node\",\"ID of to node\", \"weight\", \"timestamp\"]\n",
    "Graph = pd.read_csv(\"./datasets/Emails.csv\", names=headers, sep=' ')\n",
    "V=np.unique((Graph['ID of from node']._append(Graph['ID of to node'])).values).astype(int) # cast to int for the sake of saving to csv\n",
    "V_num = V.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test for multi edgesness\n",
    "Graph1 = Graph[Graph.duplicated(subset=[\"ID of from node\", \"ID of to node\"], keep=False)].sort_values(\"ID of from node\")\n",
    "Graph1.to_csv('Graph1.csv', index=False, columns =[\"ID of from node\",\"ID of to node\", \"timestamp\"], sep=' ')\n",
    "print(Graph1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate adjacency list for new dataset - old method\n",
    "def getValues(i):\n",
    "    return [ x[0] for x in Graph.loc[(Graph['ID of from node']==i), ['ID of to node']].drop_duplicates().values] + [ x[0] for x in Graph.loc[(Graph['ID of to node']==i), ['ID of from node']].drop_duplicates().values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate adjacency list for new dataset - old method\n",
    "matrix0 = {int(i): set(getValues(i)) for i in V}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# more adequate way of importing dataset; works faster (at least for huge dataset with about 3.5m edges)\n",
    "matrix0 = [set() for i in range(V_num + 1)]\n",
    "\n",
    "for index, row in Graph.iterrows():\n",
    "    u = int(row['ID of from node'])\n",
    "    v = int(row['ID of to node'])\n",
    "\n",
    "    if u == v: # to skip loops (in case they're present in dataset), because dissartotivity degree formula is 2m/n(n-1) (according to paper)\n",
    "        continue\n",
    "    \n",
    "    matrix0[u].add(v)\n",
    "    matrix0[v].add(u)\n",
    "\n",
    "# !!! in case adjacency list hasn't been imported !!!\n",
    "matrix = matrix0\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print adjacency list (testing purposes)\n",
    "for i in V:\n",
    "    print(i, ':', matrix0[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export generated adjacency list with whitespaces separators\n",
    "filepath = \"./adj-lists/adjacency-list-emails.csv\"\n",
    "\n",
    "with open(filepath, 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile, delimiter=' ')\n",
    "    for node in V:\n",
    "        writer.writerow([node] + list(matrix[node]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import adjacency list from csv\n",
    "matrix = [set() for i in range(V_num + 1)]\n",
    "filepath = \"./adj-lists/adjacency-list-emails.csv\"\n",
    "\n",
    "with open(filepath, 'r') as csvfile:\n",
    "    reader = csv.reader(csvfile, delimiter=' ')\n",
    "    for row in reader:\n",
    "        node = int(row[0])\n",
    "        adjacent = set(int(row[i]) for i in range(1, len(row)))\n",
    "        matrix[node] = adjacent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test matrix import\n",
    "for i in V:\n",
    "    print(matrix[i], '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Часть 1. \n",
    "# Задание 1\n",
    "E_num = 0\n",
    "\n",
    "for i in V:\n",
    "    E_num += len(matrix[i])\n",
    "\n",
    "E_num //= 2\n",
    "\n",
    "print(f'количество вершин: {V_num};\\nколичество ребер: {E_num};\\nплотность: {2*E_num/(V_num*(V_num-1))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visited = set(V)\n",
    "Component = set()\n",
    "answer = 0\n",
    "\n",
    "while len(visited):\n",
    "    answer += 1\n",
    "    v = visited.pop()\n",
    "    comp = set([v])\n",
    "    candidates = matrix[v].copy()\n",
    "    while len(candidates):\n",
    "        newCan = set()\n",
    "        for i in candidates:\n",
    "            newCan.update(matrix[i])\n",
    "        comp.update(candidates)\n",
    "        candidates = newCan.difference(comp)\n",
    "    visited -= comp\n",
    "    if len(comp) > len(Component):\n",
    "        Component = comp.copy()\n",
    "\n",
    "\n",
    "print(f'Количество компонент слабой связности: {answer};\\nРазмер максимальной компоненты: {len(Component)};\\nДоля вершин в максимальной компоненте: {len(Component)/V_num}' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Задание 3\n",
    "def Cl(u):\n",
    "    if len(matrix[u])<2:\n",
    "        return 0\n",
    "    neib = matrix[u]\n",
    "    G = len(neib)\n",
    "    _2L=0\n",
    "    for our in neib:\n",
    "        _2L+=len(matrix[our].intersection(neib))\n",
    "    return _2L/(G*(G-1))\n",
    "\n",
    "CL = 0\n",
    "for node in Component:\n",
    "    CL+=Cl(node)\n",
    "print(f'средний кластерный коэффициент сети: {CL/V_num}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Задание 4\n",
    "def R():\n",
    "    r1, r2, r3, re = 0, 0, 0, 0\n",
    "    for node in V:\n",
    "        u = len(matrix[node])\n",
    "        r1+=u\n",
    "        r2+=u*u\n",
    "        r3+=u*u*u\n",
    "        for to in matrix[node]:\n",
    "            re+=u*len(matrix[to])\n",
    "    return (re*r1-r2*r2)/(r3*r1-r2*r2)\n",
    "\n",
    "r = R()\n",
    "print(f'Коэффициент ассортативности: {r}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Задание 4 (another approach)\n",
    "def Pearson():\n",
    "    r1 = r2 = r3 = re = 0\n",
    "\n",
    "    for i in V:\n",
    "        idegree = len(matrix[i])\n",
    "        r1 += idegree\n",
    "        r2 += idegree * idegree\n",
    "        r3 += idegree * idegree * idegree\n",
    "\n",
    "        for j in V:\n",
    "            jdegree = len(matrix[j])\n",
    "            adj = (1 if j in matrix[i] else 0)\n",
    "            re += adj * idegree * jdegree\n",
    "\n",
    "    return (re * r1 - r2 * r2) / (r3 * r1 - r2 * r2)\n",
    "\n",
    "r = Pearson()\n",
    "print(f'Коэффициент ассортативности: {r}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Часть 2.\n",
    "# Статические характеристики (I)\n",
    "CN_static={} # common neighbors\n",
    "AA_static={} # adamic-adar\n",
    "JC_static={} # jaccard coefficient\n",
    "PA_static={} # preferential attachment\n",
    "visited=set()\n",
    "for adj in V:\n",
    "    visited.add(adj)\n",
    "    for node in matrix[adj]:\n",
    "        if node not in visited:\n",
    "            inter_adj_node = matrix[adj] & matrix[node]\n",
    "            CN_static[(adj, node)] = len(inter_adj_node)\n",
    "            AA_=0\n",
    "            for i in inter_adj_node:\n",
    "                AA_+=(1/np.log10(len(matrix[i])))\n",
    "            AA_static[(adj, node)] = AA_\n",
    "            JC_static[(adj, node)] = len(inter_adj_node)/len(matrix[adj].union(matrix[node]))\n",
    "            PA_static[(adj, node)] = len(matrix[adj])*len(matrix[node])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for weighting step\n",
    "t_min = Graph['timestamp'].min()\n",
    "t_max = Graph['timestamp'].max()\n",
    "t_max = (t_max-t_min)*0.75 + t_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Часть 2.\n",
    "# Построение векторов признаков для предсказания появления ребер в графе\n",
    "# create adjacency list with timestamps:\n",
    "# format [{}, {2: {t1, t2, t3, ...}}, ..., {175: {t98, ...}}]\n",
    "matrix_t = [{} for i in range(V_num + 1)]\n",
    "\n",
    "def add_time (parent, child, timestamp):\n",
    "    if child not in matrix_t[parent]:\n",
    "        timeset = set()\n",
    "        timeset.add(timestamp)\n",
    "        matrix_t[parent][child] = timeset\n",
    "    else:\n",
    "        matrix_t[parent][child].add(timestamp)\n",
    "\n",
    "for index, row in Graph.iterrows():\n",
    "    u = int(row['ID of from node'])\n",
    "    v = int(row['ID of to node'])\n",
    "    timestamp = int(row['timestamp'])\n",
    "\n",
    "    if u == v: # skip loops\n",
    "        continue\n",
    "    \n",
    "    add_time(u, v, timestamp)\n",
    "    add_time(v, u, timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test output for temporal adjacency matrix\n",
    "for i in range(len(matrix_t)):\n",
    "    print(matrix_t[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temporal features with past event aggreagtion (II-A)\n",
    "# Step A: temporal weighting\n",
    "l = 0.2 # same value as in paper\n",
    "\n",
    "def weight_linear(times):\n",
    "    weights = set()\n",
    "    for t in times:\n",
    "        T = (t - t_min) / (t_max - t_min)\n",
    "        weights.add(l + (1 - l) * T)\n",
    "    \n",
    "    return weights\n",
    "\n",
    "def weight_exp(times):\n",
    "    weights = set()\n",
    "    for t in times:\n",
    "        T = (t - t_min) / (t_max - t_min)\n",
    "        weights.add(l + (1 - l) * ((exp(3 * T) - 1) / (exp(3) - 1)))\n",
    "\n",
    "    return weights\n",
    "\n",
    "def weight_square(times):\n",
    "    weights = set()\n",
    "    for t in times:\n",
    "        T = (t - t_min) / (t_max - t_min)\n",
    "        weights.add(l + (1 - l) * sqrt(T))\n",
    "    \n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temporal features with past event aggreagtion (II-A)\n",
    "# Step B: past event aggregation\n",
    "def aggregate(weights):\n",
    "    # q-quantiles are values that partition a finite set of values into q subsets of (nearly) equal sizes\n",
    "    warr = np.array(list(weights))\n",
    "\n",
    "    zeroth = warr.min() # 0th quantile = minimum\n",
    "    first = warr.max() # 1st quantile = maximum\n",
    "    second = np.median(warr) # 2nd quantile = median\n",
    "    third = np.quantile(warr, 0.3) # 3rd quantile = tertile\n",
    "    fourth = np.quantile(warr, 0.25) # 4th quantile = quartile\n",
    "\n",
    "    sum = np.sum(warr)\n",
    "    mean = np.mean(warr)\n",
    "    variance = np.var(warr)\n",
    "\n",
    "    return [zeroth, first, second, third, fourth, sum, mean, variance]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temporal features with past event aggreagtion (II-A)\n",
    "# dict-like structure initialization: (node1, node2): [zeroth_linear, ..., variance_linear, zeroth_exp, ..., variance_exp, zeroth_sqrt, ..., variance_sqrt]\n",
    "aggregated = {}\n",
    "visited = set()\n",
    "\n",
    "for node in V:\n",
    "    visited.add(node)\n",
    "    for adj in matrix_t[node].keys():\n",
    "        if adj not in visited:\n",
    "            # convert set of timestamps into set of weights according to formulas\n",
    "            linear = weight_linear(matrix_t[node][adj])\n",
    "            exponent = weight_exp(matrix_t[node][adj])\n",
    "            square = weight_square(matrix_t[node][adj])\n",
    "\n",
    "            res = aggregate(linear)\n",
    "            res += aggregate(exponent)\n",
    "            res += aggregate(square)\n",
    "\n",
    "            aggregated[(node, adj)] = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temporal features with past event aggreagtion (II-A)\n",
    "# Step C: weighted topological features\n",
    "\n",
    "def get_aggregated(node, z, cat):\n",
    "    return aggregated[(node, z)][cat] if node < z else aggregated[(z, node)][cat]\n",
    "\n",
    "def AA_tmp(parent, child, commons, category):\n",
    "    # parent is always smaller than its child, but z - ?\n",
    "    res = 0\n",
    "\n",
    "    for z in commons:\n",
    "        num = get_aggregated(parent, z, category)\n",
    "        num += get_aggregated(child, z, category)\n",
    "\n",
    "        denum = 1\n",
    "        for x in matrix[z]:\n",
    "            denum += get_aggregated(z, x, category)\n",
    "\n",
    "        res += num / np.log10(denum)\n",
    "\n",
    "    return res\n",
    "\n",
    "def CN_tmp(parent, child, commons, category):\n",
    "    res = 0\n",
    "\n",
    "    for z in commons:\n",
    "        res += get_aggregated(parent, z, category)\n",
    "        res += get_aggregated(child, z, category)\n",
    "\n",
    "    return res\n",
    "\n",
    "def JC_tmp(parent, child, commons, category):\n",
    "    res = 0\n",
    "\n",
    "    for z in commons:\n",
    "        num = get_aggregated(parent, z, category)\n",
    "        num += get_aggregated(child, z, category)\n",
    "\n",
    "        denum = 0\n",
    "        for x in matrix[parent]:\n",
    "            denum += get_aggregated(parent, x, category)\n",
    "        for x in matrix[child]:\n",
    "            denum += get_aggregated(child, x, category)\n",
    "        \n",
    "        res += num / denum\n",
    "    \n",
    "    return res\n",
    "\n",
    "def PA_tmp(parent, child, commons, category):\n",
    "    ares = 0\n",
    "    bres = 0\n",
    "\n",
    "    for a in matrix[parent]:\n",
    "        ares += get_aggregated(parent, a, category)\n",
    "    for b in matrix[child]:\n",
    "        bres += get_aggregated(child, b, category)\n",
    "    \n",
    "    return ares * bres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temporal features with past event aggreagtion (II-A)\n",
    "# Step C: weighted topological features; 3.5k edges for approximately 2 minutes\n",
    "feature = {} # feature vector; contains 96 values\n",
    "\n",
    "for parent, child in aggregated.keys():\n",
    "    feature[(parent, child)] = []\n",
    "    for i in range(24):\n",
    "        commons = matrix[parent].intersection(matrix[child])\n",
    "        feature[(parent, child)].append(AA_tmp(parent, child, commons, i))\n",
    "        feature[(parent, child)].append(CN_tmp(parent, child, commons, i))\n",
    "        feature[(parent, child)].append(JC_tmp(parent, child, commons, i))\n",
    "        feature[(parent, child)].append(PA_tmp(parent, child, commons, i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test output for feature vector\n",
    "print(feature[(1,2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# old temporal weightning\n",
    "# for node in V:\n",
    "#     visited.add(node)\n",
    "#     for adj in matrix_t[node].keys():\n",
    "#         if adj not in visited:\n",
    "#             for t in matrix_t[adj].values():\n",
    "#                 print(t)\n",
    "                # T = (t - t_min) / (t_max - t_min)\n",
    "                # w_linear[(node, adj)] = l + (1 - l) * T\n",
    "                # w_exp[(node, adj)] = l + (1 - l)*((exp(3 * T) - 1) / (exp(3) - 1))\n",
    "                # w_sqrt[(node, adj)] = l + (1 - l) * sqrt(T)\n",
    "\n",
    "\n",
    "# for adj in V:\n",
    "#     visited.add(adj)\n",
    "#     for node in matrix_t[adj].keys():\n",
    "#         if node not in visited:\n",
    "#             for t in matrix_t[adj].values():\n",
    "#                 T = (t - t_min) / (t_max-t_min)\n",
    "#                 w_linear[(adj, node, t)] = l + (1 - l) * T\n",
    "#                 w_exp[(adj, node, t)] = l + (1 - l)*((exp(3 * T) - 1) / (exp(3) - 1))\n",
    "#                 w_sqrt[(adj, node, t)] = l + (1 - l) * sqrt(T)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c261aea317cc0286b3b3261fbba9abdec21eaa57589985bb7a274bf54d6cc0a7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
